{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75eed819",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c6562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a38d6",
   "metadata": {},
   "source": [
    "### 1.File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d2834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = 'Model/anti_cheat_model_V1'\n",
    "TEST_DATA_FILE = 'Dataset/task1/test.csv'\n",
    "OUTPUT_FILE = 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ceedd",
   "metadata": {},
   "source": [
    "### 2.Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8fa6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from 'Model/anti_cheat_model_V1'...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading model from '{MODEL_FILE}'...\")\n",
    "try:\n",
    "    # The loaded_model is the complete pipeline (imputer + lgb)\n",
    "    loaded_model = joblib.load(MODEL_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file '{MODEL_FILE}' not found.\")\n",
    "    print(\"Please run the training script first to create this file.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea90ab",
   "metadata": {},
   "source": [
    "### 3.Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb2cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from 'Dataset/task1/test.csv'...\n",
      "Test data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading test data from '{TEST_DATA_FILE}'...\")\n",
    "try:\n",
    "    test_df = pd.read_csv(TEST_DATA_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Test data file '{TEST_DATA_FILE}' not found.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"Test data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd373cdd",
   "metadata": {},
   "source": [
    "### 4.Prepare test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0677d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 31 features for prediction...\n",
      "Test data shape: (25889, 31)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    features = [col for col in test_df.columns if col not in ['id', 'player_id']]\n",
    "    X_test = test_df[features]\n",
    "    test_ids = test_df['id']\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected columns in test data: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Preparing {len(features)} features for prediction...\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35aac3d",
   "metadata": {},
   "source": [
    "### 5.Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "714bfc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on the test dataset...\n",
      "Predictions complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions on the test dataset...\")\n",
    "# The pipeline (loaded_model) will automatically handle\n",
    "# missing value imputation before predicting.\n",
    "try:\n",
    "    task1_predictions = loaded_model.predict(X_test)\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "    print(\"This might be a mismatch between the model and the test data columns.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"Predictions complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09a70d",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ccf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5350568e",
   "metadata": {},
   "source": [
    "### Add prediction to sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ba6760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ไฟล์ 'sample_submission.csv' ถูกสร้างเรียบร้อยแล้ว มี 25889 แถว\n",
      "นี่คือตัวอย่าง 5 แถวแรก:\n",
      "         id  task1  task2  task3  task4  task5\n",
      "0  ANS00001    1.0      1    0.0      1      1\n",
      "1  ANS00002    0.0      1    0.0      1      1\n",
      "2  ANS00003    1.0      1    0.0      1      1\n",
      "3  ANS00004    0.0      1    0.0      1      1\n",
      "4  ANS00005    0.0      1    0.0      1      1\n"
     ]
    }
   ],
   "source": [
    "# --- ค่าคงที่ตามเอกสารโครงการ ---\n",
    "NUM_ROWS = 25889  # จำนวนแถวทั้งหมด [cite: 756, 757]\n",
    "FILENAME = \"sample_submission.csv\"\n",
    "COLUMNS = [\"id\", \"task1\", \"task2\", \"task3\", \"task4\", \"task5\"] # \n",
    "\n",
    "# --- 1. สร้างคอลัมน์ 'id' ---\n",
    "# รูปแบบคือ ANS ตามด้วยตัวเลข 5 หลัก (เช่น 00001)\n",
    "ids = [f\"ANS{i:05d}\" for i in range(1, NUM_ROWS + 1)]\n",
    "\n",
    "# --- 2. สร้าง DataFrame พร้อมข้อมูลตัวอย่าง (Placeholder) ---\n",
    "# เราจะใช้ค่าจากตัวอย่างแถวแรกในเอกสาร  เป็นค่าเริ่มต้น\n",
    "data = {\n",
    "    \"id\": ids,\n",
    "    \"task1\": task1_predictions,\n",
    "    \"task2\": [1] * NUM_ROWS,\n",
    "    \"task3\": [0.0] * NUM_ROWS,\n",
    "    \"task4\": [1] * NUM_ROWS,\n",
    "    \"task5\": [1] * NUM_ROWS\n",
    "}\n",
    "\n",
    "# สร้าง DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# จัดลำดับคอลัมน์ให้ตรงตามเอกสาร (เผื่อไว้)\n",
    "df = df[COLUMNS]\n",
    "\n",
    "# --- 3. บันทึกเป็นไฟล์ CSV ---\n",
    "# index=False เป็นสิ่งสำคัญมากสำหรับการส่ง Kaggle \n",
    "# เพื่อไม่ให้มีคอลัมน์ index เพิ่มเข้ามา\n",
    "df.to_csv(FILENAME, index=False)\n",
    "\n",
    "print(f\"ไฟล์ '{FILENAME}' ถูกสร้างเรียบร้อยแล้ว มี {NUM_ROWS} แถว\")\n",
    "print(\"นี่คือตัวอย่าง 5 แถวแรก:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
