{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7400911b",
   "metadata": {},
   "source": [
    "# CPE342 - Karena Task1 V7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4bfe440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn & Metrics\n",
    "from sklearn.metrics import fbeta_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, IsolationForest # เพิ่ม IsolationForest\n",
    "from sklearn.pipeline import Pipeline # เปลี่ยนจาก imblearn pipeline เป็น sklearn pipeline ปกติ\n",
    "\n",
    "# Gradient Boosting Libraries\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "TARGET_COL = \"is_cheater\"\n",
    "\n",
    "# Features List (Based on your Datacard)\n",
    "DATACARD_FEATURES = [\n",
    "    \"kill_death_ratio\", \"headshot_percentage\", \"win_rate\", \"accuracy_score\", \n",
    "    \"kill_consistency\", \"reaction_time_ms\", \"account_age_days\", \"level\", \n",
    "    \"level_progression_speed\", \"friend_network_size\", \"reports_received\", \n",
    "    \"device_changes_count\", \"input_consistency_score\", \"weapon_switch_speed\", \n",
    "    \"movement_pattern_score\", \"aiming_smoothness\", \"spray_control_score\", \n",
    "    \"game_sense_score\", \"communication_rate\", \"team_play_score\", \n",
    "    \"buy_decision_score\", \"map_knowledge\", \"clutch_success_rate\", \n",
    "    \"first_blood_rate\", \"survival_time_avg\", \"damage_per_round\", \n",
    "    \"utility_usage_rate\", \"crosshair_placement\"\n",
    "]\n",
    "\n",
    "# Columns ที่ข้อมูลมีการกระจายตัวแบบเบ้ (Skewed) ที่เราจะทำ Log Transform\n",
    "LOG_COLS = ['survival_time_avg', 'damage_per_round', 'account_age_days', 'reaction_time_ms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb6fbb",
   "metadata": {},
   "source": [
    "## Load Data & Clean Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b9ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 99872\n",
      "Rows after dropping missing target: 97748\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data (แก้ Path ตามเครื่องของคุณ)\n",
    "train_df = pd.read_csv(\"C:/Users/DELL/Desktop/CPE342_Karena/Dataset/task1/train.csv\")\n",
    "test_df = pd.read_csv(\"C:/Users/DELL/Desktop/CPE342_Karena/Dataset/task1/test.csv\")\n",
    "\n",
    "# 2. Clean Target Variable\n",
    "# ลบแถวที่ไม่มีค่า Target (is_cheater) ทิ้ง\n",
    "initial_len = len(train_df)\n",
    "train_df = train_df.dropna(subset=[TARGET_COL])\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Original rows: {initial_len}\")\n",
    "print(f\"Rows after dropping missing target: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b211549",
   "metadata": {},
   "source": [
    "## Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc5dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering function updated.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_engineer_v2(df):\n",
    "    # 1. เลือกเฉพาะ Column ที่มีใน Datacard\n",
    "    available_feats = [c for c in DATACARD_FEATURES if c in df.columns]\n",
    "    df_clean = df[available_feats].copy()\n",
    "    \n",
    "    # 2. เติมค่า Missing (Median)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df_filled = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns, index=df_clean.index)\n",
    "    \n",
    "    # --- UPGRADE 1: Log Transform ---\n",
    "    # ช่วยให้โมเดลรับมือกับ Outlier ในค่าตัวเลขสูงๆ ได้ดีขึ้น\n",
    "    for col in LOG_COLS:\n",
    "        if col in df_filled.columns:\n",
    "            df_filled[f'log_{col}'] = np.log1p(df_filled[col])\n",
    "            # (Option) ถ้าอยากเก็บค่าเดิมไว้ก็ไม่ต้อง drop แต่ถ้าจะลด feature ซ้ำซ้อนให้ drop ค่าดิบทิ้ง\n",
    "            # df_filled.drop(columns=[col], inplace=True) \n",
    "\n",
    "    # --- UPGRADE 2: Context-Aware Features ---\n",
    "    \n",
    "    # 2.1 Reports Efficiency: คนเก่งฆ่าเยอะรีพอร์ตเยอะเป็นเรื่องปกติ แต่คนโกงฆ่าน้อยอาจโดนรีพอร์ตหนัก\n",
    "    df_filled['report_per_kill'] = df_filled['reports_received'] / (df_filled['kill_death_ratio'] + 1e-5)\n",
    "    \n",
    "    # 2.2 Suspicion Score: ไอดีใหม่ + ยิงหัวแม่น + ชนะบ่อย = โกงแน่ๆ\n",
    "    df_filled['sus_score'] = (df_filled['headshot_percentage'] * df_filled['win_rate']) / (df_filled['account_age_days'] + 1e-5)\n",
    "\n",
    "    # --- Original Engineered Features (เก็บตัวที่ดีไว้) ---\n",
    "    df_filled['skill_consistency'] = df_filled['game_sense_score'] / (df_filled['accuracy_score'] + 1e-5)\n",
    "    df_filled['suspicious_aim'] = df_filled['headshot_percentage'] * df_filled['reaction_time_ms']\n",
    "    df_filled['noob_movement_with_more_kills'] = df_filled['kill_death_ratio'] / (df_filled['movement_pattern_score'] + 1e-5)\n",
    "    df_filled['Aim_to_Brain_Ratio'] = (df_filled['accuracy_score'] + df_filled['headshot_percentage']) /(df_filled['map_knowledge'] + df_filled['utility_usage_rate'] + 1e-5)\n",
    "    df_filled['Sus_Headshot_Rate'] = (df_filled['headshot_percentage']) / (df_filled['crosshair_placement'] + 1e-5)\n",
    "\n",
    "    # --- Clean Noise ---\n",
    "    # ลบ Feature ที่เราวิเคราะห์แล้วว่า Correlation ต่ำมาก หรือเป็น Noise\n",
    "    noise_cols = ['friend_network_size', 'device_changes_count', 'weapon_switch_speed', 'clutch_success_rate', 'buy_decision_score']\n",
    "    df_filled = df_filled.drop(columns=[c for c in noise_cols if c in df_filled.columns], errors='ignore')\n",
    "\n",
    "    return df_filled\n",
    "\n",
    "print(\"Feature Engineering function updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061ef38",
   "metadata": {},
   "source": [
    "## Apply Engineering & Add Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66d4874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Feature Engineering...\n",
      "Training Isolation Forest to detect anomalies...\n",
      "Data Shape with Anomaly Score: (97748, 35)\n"
     ]
    }
   ],
   "source": [
    "# 1. Apply Feature Engineering\n",
    "print(\"Applying Feature Engineering...\")\n",
    "X = preprocess_and_engineer_v2(train_df)\n",
    "y = train_df[TARGET_COL]\n",
    "X_test = preprocess_and_engineer_v2(test_df)\n",
    "\n",
    "# 2. --- UPGRADE 3: Anomaly Detection Feature ---\n",
    "print(\"Training Isolation Forest to detect anomalies...\")\n",
    "\n",
    "# contamination=0.05 หมายถึงเราคาดเดาว่ามี Outlier (คนโกง/คนแปลก) ประมาณ 5%\n",
    "iso = IsolationForest(n_estimators=100, contamination=0.05, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Fit กับ Train Set\n",
    "iso.fit(X)\n",
    "\n",
    "# สร้าง Feature ใหม่: 'anomaly_score' (ยิ่งติดลบ ยิ่งแปลก)\n",
    "X['anomaly_score'] = iso.decision_function(X)\n",
    "X_test['anomaly_score'] = iso.decision_function(X_test)\n",
    "\n",
    "print(f\"Data Shape with Anomaly Score: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ff595",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da26fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Correlation Analysis Section ---\n",
    "\n",
    "# 1. เตรียมข้อมูล: นำ Features (X) และ Target (y) มารวมกันเพื่อวิเคราะห์\n",
    "df = X.copy()\n",
    "df[TARGET_COL] = y\n",
    "\n",
    "# 2. กำหนดค่าพารามิเตอร์\n",
    "CORR_METHOD = \"pearson\"          # \"pearson\" or \"spearman\" (or \"kendall\")\n",
    "\n",
    "# 3. แยก Numeric Columns\n",
    "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "# ตรวจสอบว่ามี Target อยู่ใน numeric_df หรือไม่ ถ้าไม่มีให้ดึงมาจาก df\n",
    "if TARGET_COL not in numeric_df.columns:\n",
    "    numeric_df[TARGET_COL] = df[TARGET_COL]\n",
    "\n",
    "# 4. จัดการกับ Non-Numeric Columns (ถ้ามี)\n",
    "non_num_cols = [c for c in df.columns if c not in numeric_df.columns and c != TARGET_COL]\n",
    "for c in non_num_cols:\n",
    "    try:\n",
    "        le = LabelEncoder()\n",
    "        numeric_df[c] = le.fit_transform(df[c].astype(str))\n",
    "    except Exception:\n",
    "        # if encoding fails, skip the column\n",
    "        print(f\"Warning: skipping column {c} from encoding\")\n",
    "\n",
    "# 5. Loop สร้าง Heatmap แยกตาม Class ของ Target\n",
    "unique_targets = sorted(df[TARGET_COL].unique())\n",
    "print(\"Found unique target values:\", unique_targets)\n",
    "\n",
    "for cls in unique_targets:\n",
    "    # สร้าง Binary Target สำหรับ Class นั้นๆ (One-vs-Rest)\n",
    "    bin_name = f\"target_is_{cls}\"\n",
    "    numeric_df[bin_name] = (df[TARGET_COL] == cls).astype(int)\n",
    "\n",
    "    # คำนวณ Correlation Matrix\n",
    "    corr = numeric_df.corr(method=CORR_METHOD)\n",
    "\n",
    "    # จัดลำดับ Columns ให้ target_is_X ไปอยู่ขวาสุดเพื่อให้ดูง่าย\n",
    "    cols = [c for c in corr.columns if c != bin_name and c != TARGET_COL] + [bin_name]\n",
    "    # ตัดเอาเฉพาะ Columns ที่เราสนใจ (เอา Target เดิมออก เพื่อดูเทียบกับ Binary Target ใหม่)\n",
    "    corr = corr.loc[cols, cols]\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(14, 12)) # ปรับขนาดให้ใหญ่ขึ้นเล็กน้อยเพื่อให้เห็น Label ชัดเจน\n",
    "    ax = sns.heatmap(\n",
    "        corr,\n",
    "        annot=False, # ปิดตัวเลขในช่องเพราะ Feature เยอะอาจจะลายตา (เปิด True ถ้าอยากเห็นเลข)\n",
    "        cmap='coolwarm',\n",
    "        linewidths=0.3,\n",
    "        center=0\n",
    "    )\n",
    "    ax.set_title(f\"Correlation heatmap (target = {cls}) [{CORR_METHOD}]\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # แบบใหม่ (ดูทิศทาง: บวก=ไปทาง Class นั้น, ลบ=ตรงข้าม)\n",
    "    # แสดง Top 20 features ที่มีความสัมพันธ์ทางบวก (บ่งชี้ว่าเป็น Class นี้)\n",
    "    corr_with_target = corr[bin_name].drop(bin_name).sort_values(ascending=False)\n",
    "    print(f\"\\nTop 20 features correlated with target == {cls} (Positive correlation implies trait of this class):\")\n",
    "    print(corr_with_target.head(20))\n",
    "\n",
    "    # ลบคอลัมน์ Binary ทิ้งเพื่อเตรียม Loop รอบถัดไป\n",
    "    numeric_df.drop(columns=[bin_name], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af96f44",
   "metadata": {},
   "source": [
    "## Calculate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920483be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (Normal): 63619\n",
      "Class 1 (Cheater): 34129\n",
      "Calculated scale_pos_weight for XGBoost: 1.8641\n"
     ]
    }
   ],
   "source": [
    "# นับจำนวน Class\n",
    "num_neg = (y == 0).sum()\n",
    "num_pos = (y == 1).sum()\n",
    "\n",
    "# สูตรคำนวณ: จำนวนคนปกติ / จำนวนคนโกง\n",
    "scale_pos_weight = num_neg / num_pos\n",
    "\n",
    "print(f\"Class 0 (Normal): {num_neg}\")\n",
    "print(f\"Class 1 (Cheater): {num_pos}\")\n",
    "print(f\"Calculated scale_pos_weight for XGBoost: {scale_pos_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162861ab",
   "metadata": {},
   "source": [
    "## Optuna Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda7d76",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9506141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:34:56,809] A new study created in memory with name: no-name-211bdb0c-5086-4bfc-903b-847fe02293f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning XGBoost with Class Weights (No SMOTE) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:35:04,066] Trial 0 finished with value: 0.8520897537142993 and parameters: {'n_estimators': 335, 'max_depth': 9, 'learning_rate': 0.018057312079281643, 'subsample': 0.7000778443995239, 'colsample_bytree': 0.7994198932291424, 'gamma': 3.4410812141905502, 'min_child_weight': 9}. Best is trial 0 with value: 0.8520897537142993.\n",
      "[I 2025-11-23 12:35:19,069] Trial 1 finished with value: 0.851172099597893 and parameters: {'n_estimators': 761, 'max_depth': 5, 'learning_rate': 0.06210108979742987, 'subsample': 0.9632410703009366, 'colsample_bytree': 0.9861594151463973, 'gamma': 2.4450962174639717, 'min_child_weight': 7}. Best is trial 0 with value: 0.8520897537142993.\n",
      "[I 2025-11-23 12:35:31,703] Trial 2 finished with value: 0.8479439219460515 and parameters: {'n_estimators': 625, 'max_depth': 7, 'learning_rate': 0.04458293304560393, 'subsample': 0.602069042676527, 'colsample_bytree': 0.7494632221583096, 'gamma': 3.6817654382038363, 'min_child_weight': 4}. Best is trial 0 with value: 0.8520897537142993.\n",
      "[I 2025-11-23 12:35:55,417] Trial 3 finished with value: 0.8531040829981484 and parameters: {'n_estimators': 798, 'max_depth': 8, 'learning_rate': 0.013268352267708951, 'subsample': 0.6908720440227658, 'colsample_bytree': 0.8658112458711751, 'gamma': 4.536080609659276, 'min_child_weight': 4}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:16,286] Trial 4 finished with value: 0.8530772676772594 and parameters: {'n_estimators': 946, 'max_depth': 7, 'learning_rate': 0.014239873147351251, 'subsample': 0.8188946235268815, 'colsample_bytree': 0.7883169128495051, 'gamma': 0.9315473302201044, 'min_child_weight': 10}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:22,408] Trial 5 finished with value: 0.8513680568294917 and parameters: {'n_estimators': 426, 'max_depth': 6, 'learning_rate': 0.06512556932493871, 'subsample': 0.9769005751825517, 'colsample_bytree': 0.6577462387907241, 'gamma': 2.342729471757975, 'min_child_weight': 7}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:30,973] Trial 6 finished with value: 0.8524015244533629 and parameters: {'n_estimators': 523, 'max_depth': 7, 'learning_rate': 0.030445439151574463, 'subsample': 0.9875779523792648, 'colsample_bytree': 0.6729181210162788, 'gamma': 1.6869213288541247, 'min_child_weight': 4}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:35,656] Trial 7 finished with value: 0.8479479716472283 and parameters: {'n_estimators': 417, 'max_depth': 6, 'learning_rate': 0.013002981228755652, 'subsample': 0.9961186645527234, 'colsample_bytree': 0.9524995219708813, 'gamma': 3.917518840871325, 'min_child_weight': 10}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:42,721] Trial 8 finished with value: 0.8511044578222474 and parameters: {'n_estimators': 817, 'max_depth': 3, 'learning_rate': 0.0804982882965582, 'subsample': 0.7264105703471759, 'colsample_bytree': 0.9143993708459048, 'gamma': 1.6085452566143266, 'min_child_weight': 6}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:36:54,626] Trial 9 finished with value: 0.8523847464606508 and parameters: {'n_estimators': 711, 'max_depth': 4, 'learning_rate': 0.04458133467847289, 'subsample': 0.6978250762237804, 'colsample_bytree': 0.8078982653583745, 'gamma': 0.10722825342964482, 'min_child_weight': 6}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:37:08,467] Trial 10 finished with value: 0.8513534291711221 and parameters: {'n_estimators': 993, 'max_depth': 10, 'learning_rate': 0.02279738255971184, 'subsample': 0.8470990829665831, 'colsample_bytree': 0.8817316365217934, 'gamma': 4.904380125823187, 'min_child_weight': 1}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:37:28,267] Trial 11 finished with value: 0.8529346732975919 and parameters: {'n_estimators': 925, 'max_depth': 8, 'learning_rate': 0.01026691190828742, 'subsample': 0.8370045111763668, 'colsample_bytree': 0.8457425141353703, 'gamma': 0.2093907174852505, 'min_child_weight': 2}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:37:51,042] Trial 12 finished with value: 0.8527374670852131 and parameters: {'n_estimators': 851, 'max_depth': 8, 'learning_rate': 0.016123384471957273, 'subsample': 0.7787262434510226, 'colsample_bytree': 0.7347663435976588, 'gamma': 1.091607473397938, 'min_child_weight': 4}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:38:17,498] Trial 13 finished with value: 0.8527921708198628 and parameters: {'n_estimators': 921, 'max_depth': 9, 'learning_rate': 0.011036218864326286, 'subsample': 0.611644933708047, 'colsample_bytree': 0.7554764083277244, 'gamma': 4.606734236552044, 'min_child_weight': 9}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:38:36,708] Trial 14 finished with value: 0.852069285428423 and parameters: {'n_estimators': 644, 'max_depth': 8, 'learning_rate': 0.022701436376183173, 'subsample': 0.8897149563499125, 'colsample_bytree': 0.8633295486839879, 'gamma': 0.9425146024174424, 'min_child_weight': 3}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:38:53,625] Trial 15 finished with value: 0.8516467211226034 and parameters: {'n_estimators': 848, 'max_depth': 10, 'learning_rate': 0.015281150525765518, 'subsample': 0.7746170035598509, 'colsample_bytree': 0.8096589079635319, 'gamma': 2.9037227795007556, 'min_child_weight': 8}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:39:11,698] Trial 16 finished with value: 0.8521017452705585 and parameters: {'n_estimators': 999, 'max_depth': 6, 'learning_rate': 0.02196415978636829, 'subsample': 0.6699645473387945, 'colsample_bytree': 0.9267567357605168, 'gamma': 4.196836144356333, 'min_child_weight': 5}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:39:25,558] Trial 17 finished with value: 0.8528486744591471 and parameters: {'n_estimators': 748, 'max_depth': 5, 'learning_rate': 0.03066508569206926, 'subsample': 0.9176232692612171, 'colsample_bytree': 0.7021758670983599, 'gamma': 3.1623382997360356, 'min_child_weight': 10}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:39:40,981] Trial 18 finished with value: 0.8528191111459661 and parameters: {'n_estimators': 904, 'max_depth': 9, 'learning_rate': 0.012375892686161351, 'subsample': 0.7514884893527856, 'colsample_bytree': 0.6133698771360592, 'gamma': 1.9137075523152178, 'min_child_weight': 2}. Best is trial 3 with value: 0.8531040829981484.\n",
      "[I 2025-11-23 12:39:47,993] Trial 19 finished with value: 0.852917233070043 and parameters: {'n_estimators': 583, 'max_depth': 7, 'learning_rate': 0.017898236183053896, 'subsample': 0.8082281242912557, 'colsample_bytree': 0.8437726419633768, 'gamma': 0.7185929866811329, 'min_child_weight': 5}. Best is trial 3 with value: 0.8531040829981484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB AUC: 0.8531\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb_weighted(trial):\n",
    "    params = {\n",
    "        # Hyperparameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        \n",
    "        # --- Key Config for Imbalanced Data (NO SMOTE) ---\n",
    "        'scale_pos_weight': scale_pos_weight,  # ใส่ Weight ที่คำนวณไว้\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # Pipeline แบบธรรมดา (Simple & Clean)\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', XGBClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # ใช้ scoring='roc_auc' เพื่อวัดผล\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "print(\"--- Tuning XGBoost with Class Weights (No SMOTE) ---\")\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb_weighted, n_trials=20) # รัน 20 รอบ (เพิ่มได้ถ้ามีเวลา)\n",
    "\n",
    "print(f\"Best XGB AUC: {study_xgb.best_value:.4f}\")\n",
    "best_xgb_params = study_xgb.best_params\n",
    "\n",
    "# อัปเดต params คงที่กลับเข้าไป\n",
    "best_xgb_params.update({\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1b461",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba7f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:40:23,362] A new study created in memory with name: no-name-2e9c0eea-9cbe-4a37-bfb6-4067a836ef2f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning LightGBM with Class Weights (No SMOTE) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:40:26,103] Trial 0 finished with value: 0.8531336520907034 and parameters: {'n_estimators': 911, 'learning_rate': 0.043805171514443936, 'num_leaves': 50, 'max_depth': 3, 'subsample': 0.8530235207489518, 'colsample_bytree': 0.6126932654857209, 'reg_alpha': 9.180231733788624, 'reg_lambda': 1.271471572245999, 'min_child_samples': 25}. Best is trial 0 with value: 0.8531336520907034.\n",
      "[I 2025-11-23 12:40:29,767] Trial 1 finished with value: 0.8540383094468625 and parameters: {'n_estimators': 741, 'learning_rate': 0.03104478324526414, 'num_leaves': 71, 'max_depth': 5, 'subsample': 0.7247355017652334, 'colsample_bytree': 0.7417839068062162, 'reg_alpha': 7.219998248637134, 'reg_lambda': 4.119594473324582, 'min_child_samples': 72}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:40:35,209] Trial 2 finished with value: 0.8508706315782767 and parameters: {'n_estimators': 490, 'learning_rate': 0.06624646150681625, 'num_leaves': 74, 'max_depth': 7, 'subsample': 0.6838202574264481, 'colsample_bytree': 0.7844441719792007, 'reg_alpha': 7.449561022571344, 'reg_lambda': 3.48470925116547, 'min_child_samples': 96}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:40:44,315] Trial 3 finished with value: 0.8537078651130323 and parameters: {'n_estimators': 990, 'learning_rate': 0.024482808117063146, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.9540957086735325, 'colsample_bytree': 0.7566460494921075, 'reg_alpha': 7.357069581325718, 'reg_lambda': 3.6764277683623945, 'min_child_samples': 5}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:40:57,351] Trial 4 finished with value: 0.8479678520095822 and parameters: {'n_estimators': 606, 'learning_rate': 0.07663836009106674, 'num_leaves': 61, 'max_depth': 8, 'subsample': 0.9002436827711909, 'colsample_bytree': 0.7708716067979438, 'reg_alpha': 8.23579580964193, 'reg_lambda': 3.232030069464864, 'min_child_samples': 17}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:07,199] Trial 5 finished with value: 0.8525635761034754 and parameters: {'n_estimators': 801, 'learning_rate': 0.03132017255156638, 'num_leaves': 60, 'max_depth': 7, 'subsample': 0.7425130981593284, 'colsample_bytree': 0.9670541924841719, 'reg_alpha': 5.400716817583923, 'reg_lambda': 7.1298045473535385, 'min_child_samples': 8}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:13,960] Trial 6 finished with value: 0.8536328628159149 and parameters: {'n_estimators': 703, 'learning_rate': 0.023295980415560857, 'num_leaves': 68, 'max_depth': 8, 'subsample': 0.8671926954772515, 'colsample_bytree': 0.870322070949563, 'reg_alpha': 2.68272317181107, 'reg_lambda': 2.634579147315559, 'min_child_samples': 86}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:28,971] Trial 7 finished with value: 0.8519450969297777 and parameters: {'n_estimators': 924, 'learning_rate': 0.023220533426375475, 'num_leaves': 80, 'max_depth': 10, 'subsample': 0.8006551562446764, 'colsample_bytree': 0.7031045211371788, 'reg_alpha': 4.793215993669342, 'reg_lambda': 2.8950501030297007, 'min_child_samples': 21}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:42,375] Trial 8 finished with value: 0.8501748368687908 and parameters: {'n_estimators': 656, 'learning_rate': 0.05698290733517402, 'num_leaves': 94, 'max_depth': 7, 'subsample': 0.6293833544336033, 'colsample_bytree': 0.8772864883452753, 'reg_alpha': 2.3786067187961946, 'reg_lambda': 6.158657796699717, 'min_child_samples': 67}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:54,929] Trial 9 finished with value: 0.851097712483198 and parameters: {'n_estimators': 804, 'learning_rate': 0.06048248856245814, 'num_leaves': 30, 'max_depth': 12, 'subsample': 0.84083131507467, 'colsample_bytree': 0.6555183610646454, 'reg_alpha': 8.106910718511758, 'reg_lambda': 3.3455631193151234, 'min_child_samples': 41}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:41:58,393] Trial 10 finished with value: 0.8404330742399693 and parameters: {'n_estimators': 436, 'learning_rate': 0.010820010529637455, 'num_leaves': 96, 'max_depth': 4, 'subsample': 0.7355763843149026, 'colsample_bytree': 0.8764695146467062, 'reg_alpha': 5.09864054948461, 'reg_lambda': 9.275181166788663, 'min_child_samples': 65}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:42:06,135] Trial 11 finished with value: 0.8532586289409019 and parameters: {'n_estimators': 982, 'learning_rate': 0.014642929945281427, 'num_leaves': 20, 'max_depth': 5, 'subsample': 0.9846062879632386, 'colsample_bytree': 0.7156041612608656, 'reg_alpha': 6.512098845559157, 'reg_lambda': 5.076082750327857, 'min_child_samples': 53}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:42:21,459] Trial 12 finished with value: 0.8528738854148306 and parameters: {'n_estimators': 790, 'learning_rate': 0.030952249655555448, 'num_leaves': 41, 'max_depth': 10, 'subsample': 0.9845802400817031, 'colsample_bytree': 0.7226034977802385, 'reg_alpha': 9.987649023408423, 'reg_lambda': 0.8199418448739606, 'min_child_samples': 77}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:42:26,321] Trial 13 finished with value: 0.8515472905704108 and parameters: {'n_estimators': 554, 'learning_rate': 0.017966950033697655, 'num_leaves': 45, 'max_depth': 5, 'subsample': 0.9262438658603172, 'colsample_bytree': 0.8258709977714153, 'reg_alpha': 0.13085917207977182, 'reg_lambda': 5.118241723356034, 'min_child_samples': 35}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:42:53,859] Trial 14 finished with value: 0.8496201254149577 and parameters: {'n_estimators': 872, 'learning_rate': 0.040206510010741575, 'num_leaves': 84, 'max_depth': 10, 'subsample': 0.7528441212916597, 'colsample_bytree': 0.7607294768369969, 'reg_alpha': 6.845136544544462, 'reg_lambda': 7.6130025305488465, 'min_child_samples': 52}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:43:02,900] Trial 15 finished with value: 0.8539557365346262 and parameters: {'n_estimators': 991, 'learning_rate': 0.0214498154051337, 'num_leaves': 35, 'max_depth': 5, 'subsample': 0.6089062855252766, 'colsample_bytree': 0.6875265029756662, 'reg_alpha': 6.042610387642346, 'reg_lambda': 0.14137840255920953, 'min_child_samples': 100}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:43:10,988] Trial 16 finished with value: 0.8488859135587351 and parameters: {'n_estimators': 711, 'learning_rate': 0.0971979837793647, 'num_leaves': 56, 'max_depth': 5, 'subsample': 0.6017617358448764, 'colsample_bytree': 0.6540504627413767, 'reg_alpha': 3.5896070109678853, 'reg_lambda': 0.49266340877518233, 'min_child_samples': 100}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:43:15,057] Trial 17 finished with value: 0.8482381375158394 and parameters: {'n_estimators': 755, 'learning_rate': 0.016555885921034595, 'num_leaves': 41, 'max_depth': 3, 'subsample': 0.6781668074116369, 'colsample_bytree': 0.6724863189247857, 'reg_alpha': 6.099694560437479, 'reg_lambda': 1.774230282127282, 'min_child_samples': 84}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:43:27,476] Trial 18 finished with value: 0.8521777066965397 and parameters: {'n_estimators': 865, 'learning_rate': 0.04009604400584433, 'num_leaves': 66, 'max_depth': 6, 'subsample': 0.6603799264864297, 'colsample_bytree': 0.6122841191780357, 'reg_alpha': 4.101812641517244, 'reg_lambda': 0.07609789332578298, 'min_child_samples': 71}. Best is trial 1 with value: 0.8540383094468625.\n",
      "[I 2025-11-23 12:43:31,718] Trial 19 finished with value: 0.8469196394728898 and parameters: {'n_estimators': 580, 'learning_rate': 0.013860217089402002, 'num_leaves': 33, 'max_depth': 4, 'subsample': 0.7053680840301837, 'colsample_bytree': 0.9497898229876043, 'reg_alpha': 8.514579101724662, 'reg_lambda': 8.963005552933065, 'min_child_samples': 87}. Best is trial 1 with value: 0.8540383094468625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LGBM AUC: 0.8540\n"
     ]
    }
   ],
   "source": [
    "def objective_lgbm_weighted(trial):\n",
    "    params = {\n",
    "        # Hyperparameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        \n",
    "        # --- Config for Imbalanced Data (NO SMOTE) ---\n",
    "        'class_weight': 'balanced', # ให้ LGBM จัดการ weight เองอัตโนมัติ\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    # Pipeline ธรรมดา (ไม่ต้องมี SMOTE)\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LGBMClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "print(\"--- Tuning LightGBM with Class Weights (No SMOTE) ---\")\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm_weighted, n_trials=20) \n",
    "\n",
    "print(f\"Best LGBM AUC: {study_lgbm.best_value:.4f}\")\n",
    "best_lgbm_params = study_lgbm.best_params\n",
    "\n",
    "# Update constant params\n",
    "best_lgbm_params.update({\n",
    "    'class_weight': 'balanced',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7ec5d",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8257649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:43:31,739] A new study created in memory with name: no-name-4553701c-0e1d-4a80-b827-61f775260fec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning CatBoost with Class Weights (No SMOTE) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-23 12:43:55,612] Trial 0 finished with value: 0.8539441746186921 and parameters: {'iterations': 979, 'learning_rate': 0.045213802122371326, 'depth': 4, 'l2_leaf_reg': 2.6502622363352857, 'subsample': 0.8979574675102726, 'colsample_bylevel': 0.9309948500384374}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:44:14,062] Trial 1 finished with value: 0.8530401779344018 and parameters: {'iterations': 601, 'learning_rate': 0.05279403732508587, 'depth': 7, 'l2_leaf_reg': 5.88977845512999, 'subsample': 0.8507495628753396, 'colsample_bylevel': 0.7770917390978541}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:44:33,298] Trial 2 finished with value: 0.8526194113865252 and parameters: {'iterations': 1157, 'learning_rate': 0.07582946615686256, 'depth': 4, 'l2_leaf_reg': 3.778235475208253, 'subsample': 0.6504786890623648, 'colsample_bylevel': 0.780424992328009}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:45:04,101] Trial 3 finished with value: 0.8537795351563043 and parameters: {'iterations': 1126, 'learning_rate': 0.03159763831273521, 'depth': 5, 'l2_leaf_reg': 3.1199982007777334, 'subsample': 0.6010540689313258, 'colsample_bylevel': 0.9085627925976825}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:45:24,184] Trial 4 finished with value: 0.8511979051656652 and parameters: {'iterations': 783, 'learning_rate': 0.01230956922487954, 'depth': 6, 'l2_leaf_reg': 7.158573243244681, 'subsample': 0.6044281843630493, 'colsample_bylevel': 0.7699947132726248}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:46:29,261] Trial 5 finished with value: 0.8532862903635503 and parameters: {'iterations': 1017, 'learning_rate': 0.015779930827519828, 'depth': 9, 'l2_leaf_reg': 6.469189555936084, 'subsample': 0.7281430176383623, 'colsample_bylevel': 0.9590462817870258}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:46:42,236] Trial 6 finished with value: 0.8511312647941017 and parameters: {'iterations': 644, 'learning_rate': 0.013623403377997617, 'depth': 6, 'l2_leaf_reg': 9.021451674421563, 'subsample': 0.7140506792912895, 'colsample_bylevel': 0.6959424671067597}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:48:09,171] Trial 7 finished with value: 0.8531801368579176 and parameters: {'iterations': 818, 'learning_rate': 0.026099733744812944, 'depth': 9, 'l2_leaf_reg': 9.127658193571776, 'subsample': 0.9552560779080921, 'colsample_bylevel': 0.619566888746735}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:48:50,365] Trial 8 finished with value: 0.8501002147234203 and parameters: {'iterations': 669, 'learning_rate': 0.06163684447366237, 'depth': 8, 'l2_leaf_reg': 6.541756868317555, 'subsample': 0.7371310652426196, 'colsample_bylevel': 0.9925917547163285}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:49:16,848] Trial 9 finished with value: 0.8536154281429152 and parameters: {'iterations': 1174, 'learning_rate': 0.016173331383849188, 'depth': 5, 'l2_leaf_reg': 8.524946679398795, 'subsample': 0.7286809527017809, 'colsample_bylevel': 0.7924376108740453}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:49:29,794] Trial 10 finished with value: 0.8509243846728971 and parameters: {'iterations': 981, 'learning_rate': 0.09939175993273817, 'depth': 4, 'l2_leaf_reg': 1.8919112186531937, 'subsample': 0.9986465696717851, 'colsample_bylevel': 0.860555807625414}. Best is trial 0 with value: 0.8539441746186921.\n",
      "[I 2025-11-23 12:49:45,272] Trial 11 finished with value: 0.8540684882469861 and parameters: {'iterations': 1009, 'learning_rate': 0.035131093338958745, 'depth': 5, 'l2_leaf_reg': 3.226166173144674, 'subsample': 0.8788146727361204, 'colsample_bylevel': 0.8909660858556874}. Best is trial 11 with value: 0.8540684882469861.\n",
      "[I 2025-11-23 12:49:57,231] Trial 12 finished with value: 0.8538120115815753 and parameters: {'iterations': 950, 'learning_rate': 0.04451561794834497, 'depth': 4, 'l2_leaf_reg': 1.025825243368185, 'subsample': 0.8746329445777565, 'colsample_bylevel': 0.8744839774478712}. Best is trial 11 with value: 0.8540684882469861.\n",
      "[I 2025-11-23 12:50:10,676] Trial 13 finished with value: 0.8543076970503357 and parameters: {'iterations': 878, 'learning_rate': 0.024003055644212873, 'depth': 5, 'l2_leaf_reg': 4.134970549422562, 'subsample': 0.9006345661267878, 'colsample_bylevel': 0.9315355590894289}. Best is trial 13 with value: 0.8543076970503357.\n",
      "[I 2025-11-23 12:50:29,682] Trial 14 finished with value: 0.8541093863383589 and parameters: {'iterations': 878, 'learning_rate': 0.021779422489221836, 'depth': 6, 'l2_leaf_reg': 4.444987309501619, 'subsample': 0.8120058300970158, 'colsample_bylevel': 0.8594401181934986}. Best is trial 13 with value: 0.8543076970503357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost AUC: 0.8543\n"
     ]
    }
   ],
   "source": [
    "def objective_cat_weighted(trial):\n",
    "    params = {\n",
    "        # Hyperparameters\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "        \n",
    "        # --- Config for Imbalanced Data (NO SMOTE) ---\n",
    "        'auto_class_weights': 'Balanced', # CatBoost จัดการเอง (ดีมาก)\n",
    "        'loss_function': 'Logloss', \n",
    "        'eval_metric': 'AUC',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': 0,\n",
    "        'bootstrap_type': 'Bernoulli'\n",
    "    }\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', CatBoostClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "print(\"--- Tuning CatBoost with Class Weights (No SMOTE) ---\")\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat_weighted, n_trials=15) # CatBoost ช้าหน่อย ลดรอบลงได้\n",
    "\n",
    "print(f\"Best CatBoost AUC: {study_cat.best_value:.4f}\")\n",
    "best_cat_params = study_cat.best_params\n",
    "\n",
    "# Update constant params\n",
    "best_cat_params.update({\n",
    "    'auto_class_weights': 'Balanced',\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': 0,\n",
    "    'bootstrap_type': 'Bernoulli'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e239dd7",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b62f73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fitting Weighted Stacking Model (Full Ensemble)...\n",
      "2. Predicting Test Set...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Helper Function สร้าง Pipeline\n",
    "def make_pipeline(classifier):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', classifier)\n",
    "    ])\n",
    "\n",
    "# รวม Model ที่จูนมาแล้ว (Best Params)\n",
    "estimators = [\n",
    "    ('xgb', make_pipeline(XGBClassifier(**best_xgb_params))),\n",
    "    ('lgbm', make_pipeline(LGBMClassifier(**best_lgbm_params))),\n",
    "    ('cat', make_pipeline(CatBoostClassifier(**best_cat_params)))\n",
    "]\n",
    "\n",
    "# Meta Learner (ตัวตัดสินใจขั้นสุดท้าย)\n",
    "blender = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear')\n",
    "\n",
    "# Stacking Construction\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=blender,\n",
    "    stack_method='predict_proba',\n",
    "    cv=N_FOLDS,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"1. Fitting Weighted Stacking Model (Full Ensemble)...\")\n",
    "stack_model.fit(X, y)\n",
    "\n",
    "print(\"2. Predicting Test Set...\")\n",
    "# ทำนายผลเป็น Probability เก็บไว้\n",
    "y_test_proba = stack_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d13521",
   "metadata": {},
   "source": [
    "## Threshold Optimization & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71567316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Finding Best Threshold for F2 Score...\n",
      "Optimal Threshold found: 0.1050\n",
      "Max F2 Score: 0.8160\n"
     ]
    }
   ],
   "source": [
    "print(\"3. Finding Best Threshold for F2 Score...\")\n",
    "\n",
    "# ใช้ Cross Validation Predict เพื่อหา Threshold จากข้อมูล Train\n",
    "y_train_cv_proba = cross_val_predict(stack_model, X, y, cv=N_FOLDS, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.10, 0.90, 0.005)\n",
    "f2_scores = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_temp = (y_train_cv_proba >= thresh).astype(int)\n",
    "    score = fbeta_score(y, y_pred_temp, beta=2)\n",
    "    f2_scores.append(score)\n",
    "\n",
    "best_idx = np.argmax(f2_scores)\n",
    "best_thresh = thresholds[best_idx]\n",
    "best_f2 = f2_scores[best_idx]\n",
    "\n",
    "print(f\"Optimal Threshold found: {best_thresh:.4f}\")\n",
    "print(f\"Max F2 Score: {best_f2:.4f}\")\n",
    "\n",
    "# สร้าง Final Prediction สำหรับ Test Set\n",
    "y_test_final = (y_test_proba >= best_thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec3a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to 'final_submission_v7_optimized.csv'\n",
      "          id  task1  task2          task3  task4  task5\n",
      "0   ANS00001      1      2     517.156944      1      0\n",
      "1   ANS00002      0      0    1413.611996      3      0\n",
      "2   ANS00003      1      0  158344.753397      3      1\n",
      "3   ANS00004      0      0     117.963622      0      0\n",
      "4   ANS00005      1      0     101.542132      3      0\n",
      "5   ANS00006      1      2     609.682928      2      0\n",
      "6   ANS00007      1      1       0.000000      1      0\n",
      "7   ANS00008      1      0   17357.013216      3      0\n",
      "8   ANS00009      1      0       0.000000      0      0\n",
      "9   ANS00010      0      1       0.000000      3      0\n",
      "10  ANS00011      0      2     128.685354      1      0\n",
      "11  ANS00012      0      0     432.884720      3      0\n",
      "12  ANS00013      0      0      25.834546      1      0\n",
      "13  ANS00014      0      1    1670.033716      2      0\n",
      "14  ANS00015      1      2       0.000000      4      0\n",
      "15  ANS00016      0      0       0.000000      0      0\n",
      "16  ANS00017      1      0     354.180088      3      0\n",
      "17  ANS00018      0      0       0.000000      3      0\n",
      "18  ANS00019      1      0     139.534492      0      0\n",
      "19  ANS00020      1      0     137.653094      3      0\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.read_csv(\"final_submission.csv\") # ตรวจสอบชื่อไฟล์เดิมของคุณ\n",
    "submission_df['task1'] = y_test_final\n",
    "submission_df.to_csv(\"final_submission_v7_optimized.csv\", index=False)\n",
    "print(\"Submission saved to 'final_submission_v7_optimized.csv'\")\n",
    "print(submission_df.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
